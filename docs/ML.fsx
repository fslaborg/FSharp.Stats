(**
---
title: Machine Learning
index: 22
category: Documentation
categoryindex: 0
---
*)

(*** hide ***)

(*** condition: prepare ***)
#r "nuget: FSharpAux.Core, 2.0.0"
#r "nuget: FSharpAux, 2.0.0"
#r "nuget: FSharpAux.IO, 2.0.0"
#r "nuget: OptimizedPriorityQueue, 5.1.0"
#I "../src/FSharp.Stats/bin/Release/netstandard2.0/"
#r "FSharp.Stats.dll"
#r "nuget: Plotly.NET, 4.0.0"

Plotly.NET.Defaults.DefaultDisplayOptions <-
    Plotly.NET.DisplayOptions.init (PlotlyJSReference = Plotly.NET.PlotlyJSReference.NoReference)


(*** condition: ipynb ***)
#if IPYNB
#r "nuget: Plotly.NET, 4.0.0"
#r "nuget: Plotly.NET.Interactive, 4.0.0"
#r "nuget: FSharp.Stats"

open Plotly.NET
#endif // IPYNB


(**

# Machine Learning

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/fslaborg/FSharp.Stats/gh-pages?urlpath=/tree/home/jovyan/Signal.ipynb)
[![Notebook]({{root}}img/badge-notebook.svg)]({{root}}{{fsdocs-source-basename}}.ipynb)

_Summary:_ this tutorial demonstrates functionality relevant in the context of machine learning.

## Dimensionality Reduction

### PCA

A common approach for to reduce the dimensionality of large data sets is the use of Principal component analyis.

*)
open Plotly.NET
open FSharp.Stats
open FSharp.Stats.ML.Unsupervised

let data = 
    [
        [1.0; 2.0;1.0; 2.0;];
        [1.1; 2.1;1.1; 2.1;];
        [-1.0; -2.0;1.0; 2.0;];
        [-1.1; -2.1;1.1; 2.1;];
        [-1.15; -2.15;1.15; 2.15;];
    ]
    |> FSharp.Stats.Matrix.ofJaggedList

// The PCA implementation expects column wise centered data, which can be generated by calling:
let dc = PCA.center data

// Calling compute will compute the PCA of the centered data matrix. Relevant information is stored in the result object.
let pca = PCA.compute dc

// The result of the PCA allows to visualize the analyzed data set projected onto the principal axis:

// extract components 1 and 2
let pcs = pca.PrincipalComponents |> Matrix.mapiRows (fun i v -> v.[0],v.[1])

// typical PCA "score" plot of components 1 and 2 with the explained variance indicated
let scorePlot = 
    Chart.Point(pcs)
    |> Chart.withTemplate ChartTemplates.lightMirrored
    |> Chart.withXAxisStyle (sprintf "PC1, Var explained %f" pca.VarExplainedByComponentIndividual.[0])
    |> Chart.withYAxisStyle (sprintf "PC2, Var explained %f" pca.VarExplainedByComponentIndividual.[1])
    |> Chart.withTitle "Score Plot"

(*** condition: ipynb ***)
#if IPYNB
scorePlot
#endif // IPYNB

(***hide***)
scorePlot |> GenericChart.toChartHTML
(***include-it-raw***)

// Additionally the variable loadings can be visualized:
// Disclaimer: there is a certain ambiguity when it comes to the use of the term loading.
// To stay consistent with other implementations the term loading is used.

/// Extract loadings of the variables onto the first and second principal component
let loadings = 
    pca.Loadings 
    |> Matrix.mapRows (fun v -> v.[0],v.[1])


// typical PCA "loading" plot 
let loadingPlot = 
    loadings
    |> Seq.map (fun l -> [0.,0.;l])
    |> Seq.map Chart.Line
    |> Chart.combine
    |> Chart.withTemplate ChartTemplates.lightMirrored
    |> Chart.withXAxisStyle "PC1"
    |> Chart.withYAxisStyle "PC2"
    |> Chart.withTitle "Loading Plot"

(*** condition: ipynb ***)
#if IPYNB
loadingPlot
#endif // IPYNB

(***hide***)
loadingPlot |> GenericChart.toChartHTML
(***include-it-raw***)